{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA C-MAPSS Dataset Exploration\n",
    "\n",
    "This notebook explores the NASA Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) turbofan engine degradation dataset.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The C-MAPSS dataset contains run-to-failure simulations of turbofan engines under different operating conditions and fault modes:\n",
    "\n",
    "- **FD001**: Single operating condition, single fault mode (HPC degradation)\n",
    "- **FD002**: Six operating conditions, single fault mode\n",
    "- **FD003**: Single operating condition, two fault modes (HPC + Fan degradation)\n",
    "- **FD004**: Six operating conditions, two fault modes\n",
    "\n",
    "Each dataset contains:\n",
    "- **21 sensor measurements**: Temperatures, pressures, speeds, etc.\n",
    "- **3 operational settings**: Flight conditions\n",
    "- **Time series data**: Multiple cycles until failure\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Load and understand the data structure\n",
    "2. Visualize sensor readings over time\n",
    "3. Analyze RUL distributions\n",
    "4. Identify correlations between sensors\n",
    "5. Detect degradation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "%matplotlib inline\n",
    "\n",
    "# Import custom modules\n",
    "from data_loader import CMAPSSDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "dataset_name = 'FD001'  # Change to FD002, FD003, or FD004 as needed\n",
    "\n",
    "loader = CMAPSSDataLoader(\n",
    "    data_dir='../data/CMAPSS',\n",
    "    dataset_name=dataset_name\n",
    ")\n",
    "\n",
    "# Load raw data\n",
    "train_df, test_df, test_rul = loader.load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Training units: {train_df['unit_id'].nunique()}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Test units: {test_df['unit_id'].nunique()}\")\n",
    "print(f\"\\nColumns: {train_df.shape[1]}\")\n",
    "\n",
    "# Show first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add RUL Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RUL labels to training data\n",
    "train_df = loader.add_rul_labels(train_df, max_rul=125)\n",
    "\n",
    "# Display RUL statistics\n",
    "print(\"RUL Statistics:\")\n",
    "print(train_df['RUL'].describe())\n",
    "\n",
    "# Plot RUL distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.hist(train_df['RUL'], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax1.set_xlabel('RUL (cycles)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('RUL Distribution (All Samples)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# RUL distribution per unit (last RUL value)\n",
    "unit_lifespans = train_df.groupby('unit_id')['time_cycles'].max()\n",
    "ax2.hist(unit_lifespans, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "ax2.set_xlabel('Total Lifespan (cycles)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Unit Lifespan Distribution')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sensor Readings Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample unit\n",
    "sample_unit = 1\n",
    "unit_data = train_df[train_df['unit_id'] == sample_unit]\n",
    "\n",
    "# Get sensor columns\n",
    "sensor_cols = [col for col in train_df.columns if col.startswith('sensor_')]\n",
    "\n",
    "# Plot sensor readings\n",
    "fig, axes = plt.subplots(5, 4, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, sensor in enumerate(sensor_cols):\n",
    "    if i < len(axes):\n",
    "        ax = axes[i]\n",
    "        ax.plot(unit_data['time_cycles'], unit_data[sensor], linewidth=1.5)\n",
    "        ax.set_xlabel('Time (cycles)')\n",
    "        ax.set_ylabel(sensor)\n",
    "        ax.set_title(f'{sensor} - Unit {sample_unit}')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplots\n",
    "for i in range(len(sensor_cols), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Sensor Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance for each sensor\n",
    "sensor_variance = train_df[sensor_cols].var().sort_values(ascending=False)\n",
    "\n",
    "# Plot variance\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sensor_variance.plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')\n",
    "ax.set_xlabel('Sensor')\n",
    "ax.set_ylabel('Variance')\n",
    "ax.set_title('Sensor Variance Analysis')\n",
    "ax.grid(True, axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Low variance sensors (likely to be dropped):\")\n",
    "print(sensor_variance[sensor_variance < 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "# Drop low-variance sensors first\n",
    "active_sensors = [s for s in sensor_cols if s not in loader.DROP_SENSORS]\n",
    "\n",
    "corr_matrix = train_df[active_sensors].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Correlation'},\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Sensor Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RUL vs Sensor Readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot selected sensors vs RUL\n",
    "important_sensors = ['sensor_2', 'sensor_3', 'sensor_4', 'sensor_7', 'sensor_11', 'sensor_12']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, sensor in enumerate(important_sensors):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Sample data for visualization\n",
    "    sample = train_df.sample(n=min(5000, len(train_df)))\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        sample['RUL'],\n",
    "        sample[sensor],\n",
    "        c=sample['RUL'],\n",
    "        cmap='viridis',\n",
    "        alpha=0.3,\n",
    "        s=10\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('RUL (cycles)')\n",
    "    ax.set_ylabel(sensor)\n",
    "    ax.set_title(f'{sensor} vs RUL')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.colorbar(scatter, ax=ax, label='RUL')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Degradation Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot degradation for multiple units\n",
    "sample_units = np.random.choice(train_df['unit_id'].unique(), size=5, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, sensor in enumerate(important_sensors):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    for unit in sample_units:\n",
    "        unit_data = train_df[train_df['unit_id'] == unit]\n",
    "        # Normalize time to [0, 1]\n",
    "        normalized_time = unit_data['time_cycles'] / unit_data['time_cycles'].max()\n",
    "        ax.plot(normalized_time, unit_data[sensor], alpha=0.7, label=f'Unit {unit}')\n",
    "    \n",
    "    ax.set_xlabel('Normalized Time (0=start, 1=failure)')\n",
    "    ax.set_ylabel(sensor)\n",
    "    ax.set_title(f'{sensor} Degradation Pattern')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"\\nTraining Data:\")\n",
    "print(f\"  Total samples: {len(train_df):,}\")\n",
    "print(f\"  Number of units: {train_df['unit_id'].nunique()}\")\n",
    "print(f\"  Average lifespan: {train_df.groupby('unit_id')['time_cycles'].max().mean():.1f} cycles\")\n",
    "print(f\"  Min lifespan: {train_df.groupby('unit_id')['time_cycles'].max().min()} cycles\")\n",
    "print(f\"  Max lifespan: {train_df.groupby('unit_id')['time_cycles'].max().max()} cycles\")\n",
    "\n",
    "print(f\"\\nTest Data:\")\n",
    "print(f\"  Total samples: {len(test_df):,}\")\n",
    "print(f\"  Number of units: {test_df['unit_id'].nunique()}\")\n",
    "print(f\"  Average RUL: {test_rul.mean():.1f} cycles\")\n",
    "print(f\"  Min RUL: {test_rul.min()} cycles\")\n",
    "print(f\"  Max RUL: {test_rul.max()} cycles\")\n",
    "\n",
    "print(f\"\\nSensor Information:\")\n",
    "print(f\"  Total sensors: {len(sensor_cols)}\")\n",
    "print(f\"  Active sensors (after dropping low variance): {len(active_sensors)}\")\n",
    "print(f\"  Dropped sensors: {loader.DROP_SENSORS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "From this exploration, we can observe:\n",
    "\n",
    "1. **Sensor Variability**: Some sensors have very low variance and can be dropped\n",
    "2. **Degradation Patterns**: Clear degradation trends in certain sensors as engines approach failure\n",
    "3. **Correlations**: Strong correlations between related sensors (e.g., temperature sensors)\n",
    "4. **RUL Distribution**: Most training samples have low RUL values (near failure)\n",
    "5. **Operating Conditions**: Different datasets have different levels of complexity\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Preprocess data (normalization, windowing)\n",
    "2. Build and train models\n",
    "3. Evaluate performance\n",
    "4. Analyze attention mechanisms\n",
    "5. Compare with baselines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
